{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import h5py\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(filepath):\n",
    "    data = h5py.File(filepath, 'r')\n",
    "    x_data = np.array(data['data'])\n",
    "    y_data = np.array(data['label'])\n",
    "    x_data = x_data.transpose((0,2,3,1))\n",
    "\n",
    "    return x_data, y_data\n",
    "def data_preprocess(x_data):\n",
    "    return x_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data files\n",
    "clean_test = 'data/cl/test.h5'\n",
    "clean_val = 'data/cl/valid.h5'\n",
    "bad_test = 'data/bd/bd_test.h5'\n",
    "bad_val = 'data/bd/bd_valid.h5'\n",
    "\n",
    "x_test_clean, y_test_clean = data_loader(clean_test)\n",
    "x_va_clean, y_val_clean = data_loader(clean_val)\n",
    "x_test_bd, y_test_bd = data_loader(bad_test)\n",
    "x_val_bd, y_val_bd = data_loader(bad_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load models\n",
    "model_net = 'models/bd_net.h5'\n",
    "model_weights = 'models/bd_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Classification accuracy: 98.64899974019225\n",
      "Attack Success Rate: 100.0\n"
     ]
    }
   ],
   "source": [
    "bd_model = keras.models.load_model(model_net)\n",
    "cl_label_p = np.argmax(bd_model.predict(x_va_clean), axis=1)\n",
    "clean_accuracy = np.mean(np.equal(cl_label_p, y_val_clean))\n",
    "orign_acc = clean_accuracy\n",
    "print('Clean Classification accuracy:', clean_accuracy*100)    \n",
    "bd_label_p = np.argmax(bd_model.predict(x_val_bd), axis=1)\n",
    "asr = np.mean(np.equal(bd_label_p, y_val_bd))*100\n",
    "print('Attack Success Rate:', asr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 55, 47, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv_1 (Conv2D)                (None, 52, 44, 20)   980         ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " pool_1 (MaxPooling2D)          (None, 26, 22, 20)   0           ['conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_2 (Conv2D)                (None, 24, 20, 40)   7240        ['pool_1[0][0]']                 \n",
      "                                                                                                  \n",
      " pool_2 (MaxPooling2D)          (None, 12, 10, 40)   0           ['conv_2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_3 (Conv2D)                (None, 10, 8, 60)    21660       ['pool_2[0][0]']                 \n",
      "                                                                                                  \n",
      " pool_3 (MaxPooling2D)          (None, 5, 4, 60)     0           ['conv_3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_4 (Conv2D)                (None, 4, 3, 80)     19280       ['pool_3[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 1200)         0           ['pool_3[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 960)          0           ['conv_4[0][0]']                 \n",
      "                                                                                                  \n",
      " fc_1 (Dense)                   (None, 160)          192160      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " fc_2 (Dense)                   (None, 160)          153760      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 160)          0           ['fc_1[0][0]',                   \n",
      "                                                                  'fc_2[0][0]']                   \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 160)          0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1283)         206563      ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 601,643\n",
      "Trainable params: 601,643\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bd_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repair the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  2\n",
      "0.9864899974019226\n",
      "0.9865765999826794\n",
      "0.9864899974019226\n",
      "0.9863167922404088\n",
      "0.9863167922404088\n",
      "0.9864899974019226\n",
      "0.9865765999826794\n",
      "0.9860569844981381\n",
      "0.9856239715943536\n",
      "0.9825928812678618\n",
      "0.9822464709448342\n",
      "0.9765307006148783\n",
      "0.97592448254958\n",
      "0.9579111457521434\n",
      "diff: 0.028578851649779136\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "x =  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9864899974019226\n",
      "0.9865765999826794\n",
      "0.9864899974019226\n",
      "0.9863167922404088\n",
      "0.9863167922404088\n",
      "0.9864899974019226\n",
      "0.9865765999826794\n",
      "0.9860569844981381\n",
      "0.9856239715943536\n",
      "0.9825928812678618\n",
      "0.9822464709448342\n",
      "0.9765307006148783\n",
      "0.97592448254958\n",
      "0.9579111457521434\n",
      "0.9530614012297567\n",
      "0.9486446696111545\n",
      "0.9448341560578505\n",
      "diff: 0.041655841344072075\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "x =  10\n",
      "0.9864899974019226\n",
      "0.9865765999826794\n",
      "0.9864899974019226\n",
      "0.9863167922404088\n",
      "0.9863167922404088\n",
      "0.9864899974019226\n",
      "0.9865765999826794\n",
      "0.9860569844981381\n",
      "0.9856239715943536\n",
      "0.9825928812678618\n",
      "0.9822464709448342\n",
      "0.9765307006148783\n",
      "0.97592448254958\n",
      "0.9579111457521434\n",
      "0.9530614012297567\n",
      "0.9486446696111545\n",
      "0.9448341560578505\n",
      "0.939724603793193\n",
      "0.9229237031263532\n",
      "0.894344851476574\n",
      "0.8462804191564909\n",
      "diff: 0.14020957824543168\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "x =  30\n",
      "0.9864899974019226\n",
      "0.9865765999826794\n",
      "0.9864899974019226\n",
      "0.9863167922404088\n",
      "0.9863167922404088\n",
      "0.9864899974019226\n",
      "0.9865765999826794\n",
      "0.9860569844981381\n",
      "0.9856239715943536\n",
      "0.9825928812678618\n",
      "0.9822464709448342\n",
      "0.9765307006148783\n",
      "0.97592448254958\n",
      "0.9579111457521434\n",
      "0.9530614012297567\n",
      "0.9486446696111545\n",
      "0.9448341560578505\n",
      "0.939724603793193\n",
      "0.9229237031263532\n",
      "0.894344851476574\n",
      "0.8462804191564909\n",
      "0.7698103403481423\n",
      "0.4691261799601628\n",
      "diff: 0.5173638174417597\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "X = [2, 4, 10, 30]\n",
    "for x in X:\n",
    "    print('x = ',x)\n",
    "    repaired_model = keras.models.clone_model(bd_model)\n",
    "    repaired_model.set_weights(bd_model.get_weights())\n",
    "    pruning_layer = repaired_model.get_layer('conv_3')\n",
    "    layer_model = keras.Model(inputs=repaired_model.input, outputs=repaired_model.get_layer('conv_3').output)\n",
    "    layer_pred = layer_model.predict(x_va_clean).sum(axis=(0, 1, 2))\n",
    "    id_sort = np.argsort(layer_pred)\n",
    "\n",
    "    for del_i in id_sort:\n",
    "        if layer_pred[del_i] < 1e-5: continue\n",
    "        weights = np.array(pruning_layer.get_weights()[0])\n",
    "        bias = pruning_layer.get_weights()[1]\n",
    "        weights[:, :, :, del_i] = np.zeros((3, 3, 40))\n",
    "        pruning_layer.set_weights(list([weights, bias]))\n",
    "\n",
    "        clean_pred = np.argmax(repaired_model.predict(x_va_clean), axis=1)\n",
    "        acc =  np.mean(np.equal(clean_pred, y_val_clean))\n",
    "        print(acc)\n",
    "        if(orign_acc - acc) > x/100.0:\n",
    "            print(\"diff:\", orign_acc - acc)\n",
    "            repaired_model.save('repaired_models/repaired_x{drop}.h5'.format(drop=x))\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model for x = 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Classification accuracy for clean inputs: 96.02%\n",
      "Attack Success Rate:: 100.00%\n"
     ]
    }
   ],
   "source": [
    "repaired_model = keras.models.load_model('repaired_models/repaired_x2.h5')\n",
    "clean_label_p = np.argmax(repaired_model.predict(x_test_clean), axis=1)\n",
    "poisoned_label_p = np.argmax(repaired_model.predict(x_test_bd), axis=1)\n",
    "class_accu_c = np.mean(np.equal(clean_label_p, y_test_clean))*100\n",
    "class_accu_p = np.mean(np.equal(poisoned_label_p, y_test_bd))*100\n",
    "print('Classification accuracy for clean inputs: {:.2f}%'.format(class_accu_c))\n",
    "print('Attack Success Rate:: {:.2f}%'.format(class_accu_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model for x = 4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Classification accuracy for clean inputs: 94.86%\n",
      "Attack Success Rate: 99.98%\n"
     ]
    }
   ],
   "source": [
    "repaired_model = keras.models.load_model('repaired_models/repaired_x4.h5')\n",
    "clean_label_p = np.argmax(repaired_model.predict(x_test_clean), axis=1)\n",
    "poisoned_label_p = np.argmax(repaired_model.predict(x_test_bd), axis=1)\n",
    "class_accu_c = np.mean(np.equal(clean_label_p, y_test_clean))*100\n",
    "class_accu_p = np.mean(np.equal(poisoned_label_p, y_test_bd))*100\n",
    "print('Classification accuracy for clean inputs: {:.2f}%'.format(class_accu_c))\n",
    "print('Attack Success Rate: {:.2f}%'.format(class_accu_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model for x = 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Classification accuracy for clean inputs: 84.62%\n",
      "Attack Success Rate: 76.77%\n"
     ]
    }
   ],
   "source": [
    "repaired_model = keras.models.load_model('repaired_models/repaired_x10.h5')\n",
    "clean_label_p = np.argmax(repaired_model.predict(x_test_clean), axis=1)\n",
    "poisoned_label_p = np.argmax(repaired_model.predict(x_test_bd), axis=1)\n",
    "class_accu_c = np.mean(np.equal(clean_label_p, y_test_clean))*100\n",
    "class_accu_p = np.mean(np.equal(poisoned_label_p, y_test_bd))*100\n",
    "print('Classification accuracy for clean inputs: {:.2f}%'.format(class_accu_c))\n",
    "print('Attack Success Rate: {:.2f}%'.format(class_accu_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model for x = 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Classification accuracy for clean inputs: 46.08%\n",
      "Attack Success Rate: 15.99%\n"
     ]
    }
   ],
   "source": [
    "repaired_model = keras.models.load_model('repaired_models/repaired_x30.h5')\n",
    "clean_label_p = np.argmax(repaired_model.predict(x_test_clean), axis=1)\n",
    "poisoned_label_p = np.argmax(repaired_model.predict(x_test_bd), axis=1)\n",
    "class_accu_c = np.mean(np.equal(clean_label_p, y_test_clean))*100\n",
    "class_accu_p = np.mean(np.equal(poisoned_label_p, y_test_bd))*100\n",
    "print('Classification accuracy for clean inputs: {:.2f}%'.format(class_accu_c))\n",
    "print('Attack Success Rate: {:.2f}%'.format(class_accu_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the result for x = 30%, the attack success rate drops greatly, but the classification accuracy has also dropped to an unaccecptable level. When we pruning the channel in an increasing order, at the start, the channels we prune are those insensitive channels, which means they have low contribution to the output. So the changes to those insensitive channels may not greatly impact on the attack success rate. However, if we set the x = 30%, which is big value, we would prune those channels have high contribution to the classfication. As a result, the accuracy and attack rate both drops greatly. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
